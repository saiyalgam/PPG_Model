{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "JinJuIPvijiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset: :32×32 RGB images, 10 classes\n",
        "\n",
        "\n",
        "    CNN with one convolutional layer and ReLU activation.\n",
        "    Architecture:\n",
        "    -Conv2d: 3 → 16 channels,kernel=3×3,stride=1,padding=1\n",
        "    -activation=ReLU\n",
        "\n"
      ],
      "metadata": {
        "id": "Fnj2qFbMrimD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class BasicConvNet(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels=3, out_channels=16):\n",
        "        super(BasicConvNet, self).__init__()\n",
        "\n",
        "        # Convolutional layer\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=in_channels,\n",
        "            out_channels=out_channels,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            padding=1\n",
        "        )\n",
        "\n",
        "         # ReLU activation\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Input shape (batch_size, 3, 32, 32)\n",
        "        \"\"\"\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "# CALCULATION - STEP 1:\n",
        "\n",
        "# Formula for Conv2d parameters:\n",
        "#  Parameters = (kernel_height × kernel_width × in_channels\n",
        "\n",
        "# Given:\n",
        "# in_channels = 3 (RGB)\n",
        "# out_channels = 16\n",
        "# kernel_size = 3×3\n",
        "\n",
        "# Calculation:\n",
        "# Weights = 3 × 3 × 3 × 16 = 432\n",
        "# Biases = 16\n",
        "# Total = 432 + 16 = 448 parameters\n",
        "\n",
        "# Output shape calculation:\n",
        "#H_out = (H_in + 2×padding - kernel_size) / stride + 1\n",
        "#H_out = (32 + 2×1 - 3) / 1 + 1 = 32\n",
        "#W_out = (32 + 2×1 - 3) / 1 + 1 = 32"
      ],
      "metadata": {
        "id": "y-Lp6jhgkQqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "    Extended CNN with convolutional block + FC classifier.\n",
        "    \n",
        "    Architecture:\n",
        "    - Conv2d: 3 → 16 channels, kernel=3×3, stride=1, padding=1\n",
        "    -activation=ReLU\n",
        "    -Flatten\n",
        "    -Linear: 16×32×32 → 10 (output classes)\n"
      ],
      "metadata": {
        "id": "_liyjatlsgbN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 2: Extended Network with Fully Connected Layer\n",
        "\n",
        "class ExtendedConvNet(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels=3, out_channels=16, num_classes=10):\n",
        "        super(ExtendedConvNet, self).__init__()\n",
        "\n",
        "        # Convolutional layer\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=in_channels,\n",
        "            out_channels=out_channels,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            padding=1\n",
        "        )\n",
        "\n",
        "        # ReLU activation\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # Fully connected layer\n",
        "        # Input: 16 channels × 32 height × 32 width = 16,384 features\n",
        "        self.fc = nn.Linear(\n",
        "            in_features=out_channels * 32 * 32,\n",
        "            out_features=num_classes\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        # Fully connected layer\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# PARAMETER CALCULATION - STEP 2:\n",
        "\n",
        "# 1. Convolutional Layer (from Step 1):\n",
        "#    - Parameters = 448\n",
        "\n",
        "# 2. Fully Connected Layer:\n",
        "#    Given:\n",
        "#    -in_features = 16 × 32 × 32 = 16,384\n",
        "#    -out_features = 10\n",
        "\n",
        "#    Calculation:\n",
        "#    -Weights = 16,384 × 10 = 163,840\n",
        "#    -Biases = 10\n",
        "#    -Total FC = 163,840 + 10 = 163,850 parameters\n",
        "\n",
        "# 3. TOTAL NETWORK PARAMETERS:\n",
        "#    -Conv layer: 448\n",
        "#    -FC layer: 163,850\n",
        "#    -GRAND TOTAL: 164,298 parameters\n"
      ],
      "metadata": {
        "id": "y2RWQ2sjkQso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TEST FUNCTIONS\n",
        "def test_basic_conv():\n",
        "\n",
        "\n",
        "    net = BasicConvNet(in_channels=3, out_channels=16)\n",
        "\n",
        "\n",
        "    x = torch.randn(1, 3, 32, 32)\n",
        "\n",
        "\n",
        "    y = net(x)\n",
        "\n",
        "\n",
        "    assert y.shape == (1, 16, 32, 32), f\"Expected shape (1, 16, 32, 32), got {y.shape}\"\n",
        "\n",
        "    total_params = sum(p.numel() for p in net.parameters())\n",
        "\n",
        "    print(f\"Input shape: {tuple(x.shape)}\")\n",
        "    print(f\"Output shape: {tuple(y.shape)}\")\n",
        "    print(f\"Total parameters: {total_params}\")\n",
        "    print(f\"Expected parameters: 448\")\n",
        "\n",
        "    return net\n",
        "\n"
      ],
      "metadata": {
        "id": "bXtE8KQrkQu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_extended_conv():\n",
        "\n",
        "    net = ExtendedConvNet(in_channels=3, out_channels=16, num_classes=10)\n",
        "\n",
        "\n",
        "    x = torch.randn(1, 3, 32, 32)\n",
        "\n",
        "\n",
        "    y = net(x)\n",
        "\n",
        "\n",
        "    assert y.shape == (1, 10), f\"Expected shape (1, 10), got {y.shape}\"\n",
        "\n",
        "\n",
        "    total_params = sum(p.numel() for p in net.parameters())\n",
        "\n",
        "    print(f\"Input shape: {tuple(x.shape)}\")\n",
        "    print(f\"Output shape: {tuple(y.shape)}\")\n",
        "    print(f\"Total parameters: {total_params}\")\n",
        "    print(f\"parameters: 164,298\")\n",
        "\n",
        "    # Detailed parameter breakdown\n",
        "    print(\"Parameter Breakdown:\")\n",
        "    print(\"-\" * 60)\n",
        "    for name, param in net.named_parameters():\n",
        "        print(f\"{name:20s}: {param.numel():>10,} parameters, shape {tuple(param.shape)}\")\n",
        "    print(\"-\" * 60)\n",
        "    print(f\"{'TOTAL':20s}: {total_params:>10,} parameters\\n\")\n",
        "\n",
        "    return net\n"
      ],
      "metadata": {
        "id": "X53ir0IJnfuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_batch_processing():\n",
        "    net = ExtendedConvNet()\n",
        "\n",
        "    batch_size = 8\n",
        "    x = torch.randn(batch_size, 3, 32, 32)\n",
        "    y = net(x)\n",
        "\n",
        "    assert y.shape == (batch_size, 10), f\"Expected shape ({batch_size}, 10), got {y.shape}\"\n",
        "\n",
        "    print(f\"Batch input shape: {tuple(x.shape)}\")\n",
        "    print(f\"Batch output shape: {tuple(y.shape)}\")"
      ],
      "metadata": {
        "id": "RSRMEnLmnnhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MAIN EXECUTION\n",
        "if __name__ == \"__main__\":\n",
        "    # Run all tests\n",
        "    test_basic_conv()\n",
        "    test_extended_conv()\n",
        "    test_batch_processing()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7xLIhkWkQxq",
        "outputId": "d3888c0c-2ce0-40ac-e7a6-be50d6c99877"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: (1, 3, 32, 32)\n",
            "Output shape: (1, 16, 32, 32)\n",
            "Total parameters: 448\n",
            "Expected parameters: 448\n",
            "Input shape: (1, 3, 32, 32)\n",
            "Output shape: (1, 10)\n",
            "Total parameters: 164298\n",
            "parameters: 164,298\n",
            "Parameter Breakdown:\n",
            "------------------------------------------------------------\n",
            "conv1.weight        :        432 parameters, shape (16, 3, 3, 3)\n",
            "conv1.bias          :         16 parameters, shape (16,)\n",
            "fc.weight           :    163,840 parameters, shape (10, 16384)\n",
            "fc.bias             :         10 parameters, shape (10,)\n",
            "------------------------------------------------------------\n",
            "TOTAL               :    164,298 parameters\n",
            "\n",
            "Batch input shape: (8, 3, 32, 32)\n",
            "Batch output shape: (8, 10)\n"
          ]
        }
      ]
    }
  ]
}